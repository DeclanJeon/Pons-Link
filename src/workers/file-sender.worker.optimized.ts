declare const self: DedicatedWorkerGlobalScope;

import { StreamingFileReader } from '@/lib/fileTransfer/streamingFileReader';
import { AdaptiveChecksumValidator } from '@/lib/fileTransfer/adaptiveChecksumValidator';
import { getChecksumWorkerPool } from '@/lib/fileTransfer/checksumWorkerPool';
import { PreflightAnalyzer, formatFileSize, formatETA, formatSpeed } from '@/lib/fileTransfer/preflightAnalyzer';
import { BatchAckManager } from '@/lib/fileTransfer/batchAckManager';
import { AdaptiveWindowManager } from '@/lib/fileTransfer/adaptiveWindowManager';
import { LRUChunkCache } from '@/lib/fileTransfer/lruChunkCache';
import { ProgressSmoother, formatProgress } from '@/lib/fileTransfer/progressSmoother';
import { ErrorRecoveryManager } from '@/lib/fileTransfer/errorRecoveryManager';
import { MetadataPreflight } from '@/lib/fileTransfer/metadataPreflight';

interface StartTransferPayload {
  file: File;
  transferId: string;
  chunkSize: number;
}

class OptimizedFileSender {
  private file: File | null = null;
  private transferId = '';
  private chunkSize = 64 * 1024;
  private totalChunks = 0;
  private isPaused = false;
  private isCancelled = false;
  private isSending = false;
  private startTime = 0;
  private bytesSent = 0;
  private ackedChunks = new Set<number>();
  private pendingChunks = new Map<number, { sentAt: number; retries: number }>();
  
  // ìµœì í™” ì»´í¬ë„ŒíŠ¸
  private streamingReader: StreamingFileReader | null = null;
  private checksumValidator: AdaptiveChecksumValidator | null = null;
  private checksumPool = getChecksumWorkerPool();
  private batchAckManager = new BatchAckManager();
  private windowManager = new AdaptiveWindowManager();
  private chunkCache = new LRUChunkCache();
  private progressSmoother = new ProgressSmoother();
  private errorRecovery = new ErrorRecoveryManager();
  private preflightAnalyzer = new PreflightAnalyzer(this.chunkSize);
  
  private lastProgressReport = 0;
  private readonly PROGRESS_REPORT_INTERVAL = 200;
  private readonly ACK_TIMEOUT = 15000;
  
  constructor() {
    self.onmessage = this.handleMessage.bind(this);
    this.setupOptimizations();
  }
  
  /**
   * ìµœì í™” ì»´í¬ë„ŒíŠ¸ ì„¤ì •
   */
  private setupOptimizations() {
    // ë°°ì¹˜ ACK ì½œë°±
    this.batchAckManager.onBatchAck((batchAck) => {
      self.postMessage({
        type: 'batch-ack',
        payload: batchAck
      });
    });
    
    // í”„ë¡œê·¸ë ˆìŠ¤ ìŠ¤ë¬´ë” ì½œë°±
    this.progressSmoother.onUpdate((update) => {
      this.reportProgress(update);
    });
    
    // ì—ëŸ¬ ë³µêµ¬ ì½œë°±
    this.errorRecovery.onRecovery((chunkIndex, attempt) => {
      console.log(`[OptimizedSender] Recovering chunk ${chunkIndex}, attempt ${attempt}`);
      this.retryChunk(chunkIndex);
    });
    
    this.errorRecovery.onFatalError((chunkIndex, error) => {
      console.error(`[OptimizedSender] Fatal error for chunk ${chunkIndex}:`, error);
      self.postMessage({
        type: 'error',
        payload: {
          transferId: this.transferId,
          message: `Chunk ${chunkIndex} failed permanently: ${error.message}`
        }
      });
    });
    
    this.errorRecovery.onRecoveryComplete((recoveredChunks) => {
      console.log(`[OptimizedSender] Recovery complete for ${recoveredChunks.length} chunks`);
    });
    
    console.log('[OptimizedSender] Optimization components initialized');
  }
  
  private async handleMessage(e: MessageEvent) {
    const { type, payload } = e.data;

    switch (type) {
      case 'start-transfer':
        await this.startTransfer(payload);
        break;
      case 'pause-transfer':
        this.isPaused = true;
        break;
      case 'resume-transfer':
        this.isPaused = false;
        this.sendNextBatch();
        break;
      case 'cancel-transfer':
        this.cancel();
        break;
      case 'ack-received':
        this.handleAck(payload);
        break;
      case 'batch-ack-received':
        this.handleBatchAck(payload);
        break;
      case 'receiver-complete':
        this.handleReceiverComplete(payload);
        break;
    }
  }
  
  /**
   * ì „ì†¡ ì‹œìž‘ (ìµœì í™”ëœ ë²„ì „)
   */
  private async startTransfer(payload: StartTransferPayload) {
    this.file = payload.file;
    this.transferId = payload.transferId;
    this.chunkSize = payload.chunkSize;
    this.totalChunks = Math.ceil(this.file.size / this.chunkSize);
    this.startTime = Date.now();
    this.bytesSent = 0;
    this.ackedChunks.clear();
    this.pendingChunks.clear();
    this.lastProgressReport = Date.now();
    
    // ìŠ¤íŠ¸ë¦¬ë° ë¦¬ë” ì´ˆê¸°í™”
    this.streamingReader = new StreamingFileReader(this.file, this.chunkSize);
    
    // ì²´í¬ì„¬ ê²€ì¦ê¸° ì´ˆê¸°í™”
    this.checksumValidator = new AdaptiveChecksumValidator(this.file.size, this.chunkSize);
    
    // í”„ë¦¬í”Œë¼ì´íŠ¸ ë¶„ì„ ì‹œìž‘
    this.preflightAnalyzer.onProgress((report) => {
      self.postMessage({
        type: 'preflight-progress',
        payload: {
          transferId: this.transferId,
          stage: report.stage,
          progress: report.progress,
          quick: report.quick,
          detailed: report.detailed
        }
      });
    });
    
    const preflightReport = await this.preflightAnalyzer.analyzeFile(this.file);
    
    // ë©”íƒ€ë°ì´í„° ì„ ì „ì†¡
    const preflightPacket = await new MetadataPreflight(this.chunkSize).prepareTransfer(this.file, this.transferId);
    const serializedPacket = MetadataPreflight.serializePacket(preflightPacket);
    
    self.postMessage({
      type: 'preflight-ready',
      payload: {
        transferId: this.transferId,
        packet: serializedPacket,
        analysis: preflightReport
      }
    }, [serializedPacket]);
    
    // ì²« ë²ˆì§¸ ì²­í¬ê°€ í¬í•¨ë˜ì–´ ìžˆìœ¼ë©´ ACK ëª©ë¡ì— ì¶”ê°€
    if (preflightPacket.firstChunk) {
      this.ackedChunks.add(0);
      this.bytesSent += preflightPacket.firstChunk.size;
    }
    
    console.log(`[OptimizedSender] ðŸš€ Starting optimized transfer:`, {
      fileName: this.file.name,
      fileSize: this.file.size,
      chunkSize: this.chunkSize,
      totalChunks: this.totalChunks,
      checksumStrategy: this.checksumValidator.getSamplingInfo()
    });
    
    this.sendNextBatch();
  }
  
  /**
   * ë‹¤ìŒ ë°°ì¹˜ ì „ì†¡
   */
  private async sendNextBatch() {
    if (this.isPaused || this.isCancelled || !this.file || this.isSending) return;
    
    this.isSending = true;
    
    try {
      const windowSize = this.windowManager.getWindowSize();
      let sentCount = 0;
      
      // ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ì „ì†¡
      if (this.streamingReader) {
        for await (const chunk of this.streamingReader.readChunks()) {
          // ì´ë¯¸ ACK ë°›ì€ ì²­í¬ëŠ” ìŠ¤í‚µ
          if (this.ackedChunks.has(chunk.index)) continue;
          
          // ì´ë¯¸ ì „ì†¡ ì¤‘ì¸ ì²­í¬ëŠ” ìŠ¤í‚µ
          if (this.pendingChunks.has(chunk.index)) continue;
          
          // ìœˆë„ìš° í¬ê¸° ì œí•œ
          if (this.pendingChunks.size >= windowSize) break;
          
          // ì²´í¬ì„¬ ê²€ì¦ì´ í•„ìš”í•œ ì²­í¬ë§Œ ê³„ì‚°
          let checksum: string | undefined;
          if (this.checksumValidator && this.checksumValidator.shouldValidate(chunk.index)) {
            checksum = await this.checksumPool.calculateChecksum(chunk.data);
          }
          
          // ì²­í¬ ì „ì†¡
          await this.sendChunk(chunk.index, chunk.data, checksum, chunk.isLast);
          sentCount++;
          
          // ë§ˆì§€ë§‰ ì²­í¬ì´ë©´ ë£¨í”„ ì¢…ë£Œ
          if (chunk.isLast) break;
        }
      }
      
      console.log(`[OptimizedSender] ðŸ“¤ Sent batch: ${sentCount} chunks, window: ${windowSize}`);
      
    } finally {
      this.isSending = false;
    }
  }
  
  /**
   * ì²­í¬ ì „ì†¡
   */
  private async sendChunk(
    chunkIndex: number, 
    data: ArrayBuffer, 
    checksum?: string, 
    isLast: boolean = false
  ) {
    if (!this.file) return;
    
    const expectedSize = isLast
      ? this.file.size - chunkIndex * this.chunkSize
      : this.chunkSize;
    
    if (data.byteLength !== expectedSize) {
      console.error(`[OptimizedSender] âŒ Chunk size mismatch at ${chunkIndex}:`, {
        expected: expectedSize,
        actual: data.byteLength,
      });
      return;
    }
    
    // íŒ¨í‚· ìƒì„±
    const packet = this.createPacket(chunkIndex, data, checksum || '');
    
    // ìºì‹œì— ì €ìž¥
    this.chunkCache.set(chunkIndex, data);
    
    // ì „ì†¡ ê¸°ë¡
    this.pendingChunks.set(chunkIndex, {
      sentAt: Date.now(),
      retries: 0
    });
    
    // íƒ€ìž„ì•„ì›ƒ ì„¤ì •
    setTimeout(() => {
      this.handleTimeout(chunkIndex);
    }, this.ACK_TIMEOUT);
    
    // ì „ì†¡
    self.postMessage({
      type: 'chunk-ready',
      payload: {
        transferId: this.transferId,
        chunkIndex,
        chunk: packet,
        isLast,
      },
    }, [packet]);
    
    console.log(`[OptimizedSender] ðŸ“¤ Sending chunk ${chunkIndex}/${this.totalChunks - 1}, size: ${data.byteLength} bytes${isLast ? ' (LAST)' : ''}`);
  }
  
  /**
   * ì²­í¬ ìž¬ì‹œë„
   */
  private async retryChunk(chunkIndex: number) {
    if (!this.streamingReader) return;
    
    const chunkData = await this.streamingReader.readChunk(chunkIndex);
    if (!chunkData) {
      console.error(`[OptimizedSender] âŒ Failed to re-read chunk ${chunkIndex}`);
      return;
    }
    
    // ì²´í¬ì„¬ ê³„ì‚°
    let checksum: string | undefined;
    if (this.checksumValidator && this.checksumValidator.shouldValidate(chunkIndex)) {
      checksum = await this.checksumPool.calculateChecksum(chunkData);
    }
    
    const isLast = chunkIndex === this.totalChunks - 1;
    await this.sendChunk(chunkIndex, chunkData, checksum, isLast);
  }
  
  /**
   * íŒ¨í‚· ìƒì„±
   */
  private createPacket(chunkIndex: number, data: ArrayBuffer, checksum: string): ArrayBuffer {
    const idBytes = new TextEncoder().encode(this.transferId);
    const checksumBytes = new TextEncoder().encode(checksum);
    
    const headerSize = 1 + 2 + idBytes.length + 4 + 4 + 2 + checksumBytes.length;
    const totalSize = headerSize + data.byteLength;
    const packet = new ArrayBuffer(totalSize);
    const view = new DataView(packet);

    let offset = 0;
    
    view.setUint8(offset, 1);
    offset += 1;
    
    view.setUint16(offset, idBytes.length, false);
    offset += 2;
    
    new Uint8Array(packet, offset, idBytes.length).set(idBytes);
    offset += idBytes.length;
    
    view.setUint32(offset, chunkIndex, false);
    offset += 4;
    
    view.setUint32(offset, data.byteLength, false);
    offset += 4;
    
    view.setUint16(offset, checksumBytes.length, false);
    offset += 2;
    
    new Uint8Array(packet, offset, checksumBytes.length).set(checksumBytes);
    offset += checksumBytes.length;
    
    const dataView = new Uint8Array(data);
    new Uint8Array(packet, offset, data.byteLength).set(dataView);

    return packet;
  }
  
  /**
   * ê°œë³„ ACK ì²˜ë¦¬
   */
  private handleAck(payload: { chunkIndex: number }) {
    const { chunkIndex } = payload;
    
    if (this.ackedChunks.has(chunkIndex)) {
      return;
    }
    
    if (chunkIndex >= this.totalChunks) {
      console.error(`[OptimizedSender] âŒ Invalid ACK: chunk ${chunkIndex} >= totalChunks ${this.totalChunks}`);
      return;
    }
    
    this.ackedChunks.add(chunkIndex);
    this.pendingChunks.delete(chunkIndex);
    this.chunkCache.removeAcked(chunkIndex);
    this.errorRecovery.handleChunkSuccess(chunkIndex);
    
    const chunkBytes = Math.min(
      this.chunkSize,
      this.file!.size - chunkIndex * this.chunkSize
    );
    this.bytesSent += chunkBytes;
    
    // ìœˆë„ìš° ê´€ë¦¬ìžì— ì•Œë¦¼
    const rtt = Date.now() - (this.pendingChunks.get(chunkIndex)?.sentAt || Date.now());
    this.windowManager.onAckReceived(rtt);
    
    // ë°°ì¹˜ ACKì— ì¶”ê°€
    this.batchAckManager.addAck(this.transferId, chunkIndex);
    
    // í”„ë¡œê·¸ë ˆìŠ¤ ì—…ë°ì´íŠ¸
    const progress = this.bytesSent / this.file!.size;
    const speed = this.bytesSent / ((Date.now() - this.startTime) / 1000);
    const eta = (this.file!.size - this.bytesSent) / speed;
    
    this.progressSmoother.setTarget(progress, speed, eta);
    
    console.log(`[OptimizedSender] âœ… ACK received for chunk ${chunkIndex}, total ACKed: ${this.ackedChunks.size}/${this.totalChunks}`);
    
    if (this.ackedChunks.size === this.totalChunks) {
      console.log(`[OptimizedSender] ðŸŽ‰ All chunks ACKed!`);
      this.progressSmoother.setTarget(1.0);
      this.batchAckManager.flush(this.transferId);
    } else if (!this.isSending) {
      this.sendNextBatch();
    }
  }
  
  /**
   * ë°°ì¹˜ ACK ì²˜ë¦¬
   */
  private handleBatchAck(payload: any) {
    const acks = BatchAckManager.parseBatchAck(payload);
    
    for (const chunkIndex of acks) {
      if (!this.ackedChunks.has(chunkIndex)) {
        this.handleAck({ chunkIndex });
      }
    }
    
    console.log(`[OptimizedSender] ðŸ“¦ Processed batch ACK: ${acks.length} chunks`);
  }
  
  /**
   * íƒ€ìž„ì•„ì›ƒ ì²˜ë¦¬
   */
  private async handleTimeout(chunkIndex: number) {
    const pending = this.pendingChunks.get(chunkIndex);
    if (!pending || this.isCancelled) return;
    
    // ì—ëŸ¬ ë³µêµ¬ ê´€ë¦¬ìžì— ìœ„ìž„
    const canRecover = await this.errorRecovery.handleChunkError(
      chunkIndex, 
      new Error(`Timeout after ${this.ACK_TIMEOUT}ms`)
    );
    
    if (canRecover) {
      // ìœˆë„ìš° ê´€ë¦¬ìžì— íŒ¨í‚· ì†ì‹¤ ì•Œë¦¼
      this.windowManager.onPacketLoss();
      
      // ìž¬ì‹œë„ëŠ” ì—ëŸ¬ ë³µêµ¬ ê´€ë¦¬ìžê°€ ì²˜ë¦¬
    } else {
      console.error(`[OptimizedSender] âŒ Chunk ${chunkIndex} failed permanently`);
      
      self.postMessage({
        type: 'error',
        payload: {
          transferId: this.transferId,
          message: `Chunk ${chunkIndex} failed after multiple retries`,
        },
      });
      
      this.cancel();
    }
  }
  
  /**
   * ìˆ˜ì‹ ìž ì™„ë£Œ ì²˜ë¦¬
   */
  private handleReceiverComplete(payload: { transferId: string }) {
    if (payload.transferId === this.transferId && !this.isCancelled) {
      console.log(`[OptimizedSender] âœ… Receiver confirmed assembly complete`);
      
      this.progressSmoother.setTarget(1.0);
      this.complete();
    }
  }
  
  /**
   * í”„ë¡œê·¸ë ˆìŠ¤ ë³´ê³ 
   */
  private reportProgress(update: any) {
    const now = Date.now();
    if (now - this.lastProgressReport >= this.PROGRESS_REPORT_INTERVAL) {
      const remaining = this.file ? this.file.size - this.bytesSent : 0;
      
      self.postMessage({
        type: 'progress',
        payload: {
          transferId: this.transferId,
          progress: update.progress,
          actualProgress: this.bytesSent / (this.file?.size || 1),
          speed: update.speed || 0,
          eta: update.eta || Infinity,
          bytesSent: this.bytesSent,
          chunksSent: this.ackedChunks.size,
          totalChunks: this.totalChunks,
          pendingChunks: this.pendingChunks.size,
          windowSize: this.windowManager.getWindowSize(),
          cacheStats: this.chunkCache.getStats(),
          recoveryStats: this.errorRecovery.getRecoveryStats()
        },
      });
      
      this.lastProgressReport = now;
    }
  }
  
  /**
   * ì „ì†¡ ì™„ë£Œ
   */
  private complete() {
    const totalTime = (Date.now() - this.startTime) / 1000;
    const averageSpeed = totalTime > 0 ? this.bytesSent / totalTime : 0;

    console.log(`[OptimizedSender] ðŸŽŠ Transfer complete:`, {
      transferId: this.transferId,
      totalTime: `${totalTime.toFixed(2)}s`,
      averageSpeed: `${(averageSpeed / 1024 / 1024).toFixed(2)} MB/s`,
      totalChunks: this.totalChunks,
      ackedChunks: this.ackedChunks.size,
      cacheStats: this.chunkCache.getStats(),
      recoveryStats: this.errorRecovery.getRecoveryStats()
    });

    self.postMessage({
      type: 'complete',
      payload: {
        transferId: this.transferId,
        averageSpeed,
        totalTime,
        stats: {
          cacheStats: this.chunkCache.getStats(),
          recoveryStats: this.errorRecovery.getRecoveryStats(),
          windowStats: this.windowManager.getWindowState()
        }
      },
    });
    
    this.cleanup();
  }
  
  /**
   * ì·¨ì†Œ
   */
  private cancel() {
    this.isCancelled = true;
    this.pendingChunks.clear();
    this.batchAckManager.cleanup(this.transferId);
    
    self.postMessage({
      type: 'cancelled',
      payload: { transferId: this.transferId },
    });
    
    this.cleanup();
  }
  
  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  private cleanup() {
    if (this.streamingReader) {
      this.streamingReader.cleanup();
      this.streamingReader = null;
    }
    
    this.chunkCache.clear();
    this.progressSmoother.stop();
    this.errorRecovery.reset();
    this.windowManager.reset();
    
    console.log('[OptimizedSender] Resources cleaned up');
  }
}

new OptimizedFileSender();