/**
 * @fileoverview ì ì‘í˜• ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ì - iOS MediaRecorder ì „ëµ í¬í•¨ ì™„ì „ êµ¬í˜„
 * @module services/adaptiveStreamManager
 * @description ë¹„ë””ì˜¤, PDF, ì´ë¯¸ì§€ ëª¨ë‘ ì§€ì›í•˜ëŠ” í†µí•© ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ì
 */

import {
  selectStreamingStrategy,
  StreamingStrategy,
  StrategySelection,
  StreamingConfig
} from '@/lib/media/streamingStrategy';
import { MediaRecorderStreaming, MediaRecorderStreamingEvents } from './mediaRecorderStreaming';
import { getDeviceInfo } from '@/lib/device/deviceDetector';
import { toast } from 'sonner';
import { useSubtitleStore } from '@/stores/useSubtitleStore';
import { useFileStreamingStore } from '@/stores/useFileStreamingStore';

/**
 * ìŠ¤íŠ¸ë¦¼ ìƒì„± ê²°ê³¼ ì¸í„°í˜ì´ìŠ¤
 */
export interface StreamCreationResult {
  stream: MediaStream;
  strategy: StreamingStrategy;
  config: StreamingConfig;
  cleanup: () => void;
}

/**
 * ì ì‘í˜• ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ì í´ë˜ìŠ¤
 */
export class AdaptiveStreamManager {
  private currentStrategy: StrategySelection;
  private mediaRecorderStreaming: MediaRecorderStreaming | null = null;
  private canvasAnimationId: number | null = null;
  private currentStream: MediaStream | null = null;
  private staticContentCanvas: HTMLCanvasElement | null = null;
  private dummyVideoElement: HTMLVideoElement | null = null;
  
  constructor() {
    this.currentStrategy = selectStreamingStrategy();
    
    if (process.env.NODE_ENV === 'development') {
      console.log('[AdaptiveStreamManager] Initialized with strategy:', this.currentStrategy.strategy);
    }
  }
  
  /**
   * ë””ë°”ì´ìŠ¤ ë° ì „ëµ ì •ë³´ ë°˜í™˜
   */
  getInfo(): { device: ReturnType<typeof getDeviceInfo>; strategy: StrategySelection } {
    return {
      device: getDeviceInfo(),
      strategy: this.currentStrategy
    };
  }
  
  /**
   * ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± (ê¸°ì¡´ ë¡œì§)
   */
  async createStream(
    videoElement: HTMLVideoElement,
    onChunkReady?: (blob: Blob, timestamp: number) => void,
    options?: { embedSubtitles?: boolean }
  ): Promise<StreamCreationResult> {
    const { strategy, config, fallbacks } = this.currentStrategy;
    
    if (process.env.NODE_ENV === 'development') {
      console.log(`[AdaptiveStreamManager] Creating stream with strategy: ${strategy}`);
    }
    
    // ìë§‰ ì„ë² ë“œ ì˜µì…˜ì´ ìˆìœ¼ë©´ ìº”ë²„ìŠ¤ ê²½ë¡œë¥¼ ê°•ì œë¡œ ì‚¬ìš©
    if (options?.embedSubtitles) {
      return await this.createCanvasStream(videoElement, config, { withSubtitles: true });
    }
    
    try {
      switch (strategy) {
        case 'mediarecorder':
          return await this.createMediaRecorderStream(videoElement, config, onChunkReady);
        
        case 'capturestream':
          return await this.createCaptureStream(videoElement, config);
        
        case 'canvas':
          return await this.createCanvasStream(videoElement, config);
        
        default:
          throw new Error(`Unknown strategy: ${strategy}`);
      }
    } catch (error) {
      console.error(`[AdaptiveStreamManager] Strategy ${strategy} failed:`, error);
      
      for (const fallbackStrategy of fallbacks) {
        console.log(`[AdaptiveStreamManager] Trying fallback: ${fallbackStrategy}`);
        
        try {
          switch (fallbackStrategy) {
            case 'capturestream':
              return await this.createCaptureStream(videoElement, config);
            
            case 'canvas':
              return await this.createCanvasStream(videoElement, config);
          }
        } catch (fallbackError) {
          console.error(`[AdaptiveStreamManager] Fallback ${fallbackStrategy} failed:`, fallbackError);
          continue;
        }
      }
      
      throw new Error('All streaming strategies failed');
    }
  }

  /**
   * ì •ì  ì½˜í…ì¸ (PDF/ì´ë¯¸ì§€) ìŠ¤íŠ¸ë¦¼ ìƒì„±
   * @param canvas - ë Œë”ë§ëœ Canvas ìš”ì†Œ
   * @param onChunkReady - MediaRecorder ì‚¬ìš© ì‹œ ì²­í¬ ì½œë°±
   */
  async createStaticStream(
    canvas: HTMLCanvasElement,
    onChunkReady?: (blob: Blob, timestamp: number) => void
  ): Promise<StreamCreationResult> {
    console.log('[AdaptiveStreamManager] Creating static content stream (PDF/Image)');
    
    this.staticContentCanvas = canvas;
    const { strategy, config, fallbacks } = this.currentStrategy;
    
    // ì •ì  ì½˜í…ì¸ ìš© ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    const staticConfig: StreamingConfig = {
      ...config,
      fps: 3,
      videoBitsPerSecond: Math.floor(config.videoBitsPerSecond * 0.5),
      audioBitsPerSecond: 0,
      timeslice: 1000,
      chunkSize: 16 * 1024
    };
    
    try {
      switch (strategy) {
        case 'mediarecorder':
          return await this.createStaticMediaRecorderStream(canvas, staticConfig, onChunkReady);
        
        case 'capturestream':
          return await this.createStaticCaptureStream(canvas, staticConfig);
        
        case 'canvas':
          return await this.createStaticCanvasStream(canvas, staticConfig);
        
        default:
          throw new Error(`Unknown strategy: ${strategy}`);
      }
    } catch (error) {
      console.error(`[AdaptiveStreamManager] Static stream strategy ${strategy} failed:`, error);
      
      for (const fallbackStrategy of fallbacks) {
        try {
          switch (fallbackStrategy) {
            case 'capturestream':
              return await this.createStaticCaptureStream(canvas, staticConfig);
            case 'canvas':
              return await this.createStaticCanvasStream(canvas, staticConfig);
          }
        } catch (fallbackError) {
          continue;
        }
      }
      
      throw new Error('All static streaming strategies failed');
    }
  }

  /**
   * ì •ì  ì½˜í…ì¸ ìš© MediaRecorder ìŠ¤íŠ¸ë¦¼ (iOS 14.3+ ìµœì í™”)
   */
  private async createStaticMediaRecorderStream(
    canvas: HTMLCanvasElement,
    config: StreamingConfig,
    onChunkReady?: (blob: Blob, timestamp: number) => void
  ): Promise<StreamCreationResult> {
    console.log('[AdaptiveStreamManager] Using MediaRecorder for static content (iOS optimized)');

    // Canvasì—ì„œ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    let videoStream: MediaStream;
    if ('captureStream' in canvas) {
      videoStream = (canvas as any).captureStream(config.fps);
    } else if ('mozCaptureStream' in canvas) {
      videoStream = (canvas as any).mozCaptureStream(config.fps);
    } else {
      throw new Error('Canvas captureStream not supported');
    }

    if (!videoStream || videoStream.getTracks().length === 0) {
      throw new Error('Failed to create base stream from canvas');
    }

    // âœ… íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ì›ë³¸ ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ê°€ì ¸ì˜¤ê¸°
    const fileStreamingStore = useFileStreamingStore.getState();
    const videoEl = fileStreamingStore.presentationVideoEl;
    let audioTrack: MediaStreamTrack | null = null;

    if (fileStreamingStore.isStreaming && videoEl && !videoEl.muted) {
      console.log('[AdaptiveStreamManager] ğŸµ Attempting to capture audio from file streaming video');

      try {
        // 1. captureStreamìœ¼ë¡œ ì˜¤ë””ì˜¤ ì‹œë„
        let capturedStream: MediaStream | null = null;
        if (typeof (videoEl as any).captureStream === 'function') {
          capturedStream = (videoEl as any).captureStream();
        } else if (typeof (videoEl as any).mozCaptureStream === 'function') {
          capturedStream = (videoEl as any).mozCaptureStream();
        }

        audioTrack = capturedStream?.getAudioTracks()[0] || null;
        if (audioTrack) {
          console.log('[AdaptiveStreamManager] âœ… Audio track from captureStream');
        }

        // 2. VideoJsPlayerì—ì„œ ë¯¸ë¦¬ ì¤€ë¹„ëœ AudioContext ì‚¬ìš©
        if (!audioTrack && (videoEl as any)._audioDestination) {
          try {
            const dest = (videoEl as any)._audioDestination;
            audioTrack = dest.stream.getAudioTracks()[0] || null;
            if (audioTrack) {
              console.log('[AdaptiveStreamManager] âœ… Audio track from prepared AudioContext');
            }
          } catch (e) {
            console.error('[AdaptiveStreamManager] Prepared AudioContext failed:', e);
          }
        }

        // 3. AudioContext Fallback
        if (!audioTrack) {
          const ctx = new AudioContext();
          const src = ctx.createMediaElementSource(videoEl);
          const dest = ctx.createMediaStreamDestination();

          // âœ… ê²Œì¸ ë…¸ë“œ ì¶”ê°€
          const gainNode = ctx.createGain();
          gainNode.gain.value = 1.0;

          src.connect(gainNode);
          gainNode.connect(dest);

          audioTrack = dest.stream.getAudioTracks()[0] || null;
          console.log('[AdaptiveStreamManager] âœ… Audio captured via AudioContext');

          // ì •ë¦¬ë¥¼ ìœ„í•´ AudioContext ì €ì¥
          (canvas as any)._audioContext = ctx;
        }
      } catch (e) {
        console.error('[AdaptiveStreamManager] Audio capture failed:', e);
      }
    }

    // âœ… ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ ê²°í•©
    const combinedStream = new MediaStream();
    videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));

    if (audioTrack) {
      combinedStream.addTrack(audioTrack);
      console.log('[AdaptiveStreamManager] âœ… Audio track added to MediaRecorder stream');
    } else {
      console.log('[AdaptiveStreamManager] âš ï¸ No audio track available (streaming static content only)');
    }

    // ê°€ìƒ ë¹„ë””ì˜¤ ìš”ì†Œ ìƒì„± (ê²°í•©ëœ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©)
    this.dummyVideoElement = document.createElement('video');
    this.dummyVideoElement.srcObject = combinedStream;
    this.dummyVideoElement.muted = true;
    this.dummyVideoElement.playsInline = true;

    try {
      await this.dummyVideoElement.play();
    } catch (playError) {
      console.warn('[AdaptiveStreamManager] Dummy video play failed:', playError);
    }
    
    // MediaRecorder ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    const events: MediaRecorderStreamingEvents = {
      onChunkReady: (blob: Blob, timestamp: number) => {
        if (onChunkReady) {
          onChunkReady(blob, timestamp);
        }
      },
      onError: (error: Error) => {
        console.error('[AdaptiveStreamManager] MediaRecorder error:', error);
        toast.error(`Streaming error: ${error.message}`);
      },
      onStateChange: (state: 'inactive' | 'recording' | 'paused') => {
        if (process.env.NODE_ENV === 'development') {
          console.log('[AdaptiveStreamManager] MediaRecorder state:', state);
        }
      },
      onBitrateUpdate: (bitrate: number) => {
        if (bitrate < 100000) {
          console.warn('[AdaptiveStreamManager] Low bitrate detected:', bitrate);
        }
      }
    };
    
    this.mediaRecorderStreaming = new MediaRecorderStreaming(events);
    
    try {
      await this.mediaRecorderStreaming.start(this.dummyVideoElement, config);
      
      // ë”ë¯¸ ìŠ¤íŠ¸ë¦¼ ë°˜í™˜ (ì‹¤ì œ ì „ì†¡ì€ MediaRecorderê°€ ì²˜ë¦¬)
      const dummyStream = new MediaStream();
      this.currentStream = dummyStream;
      
      toast.success('Static content streaming started (iOS MediaRecorder)', { duration: 2000 });
      
      return {
        stream: dummyStream,
        strategy: 'mediarecorder',
        config,
        cleanup: () => {
          if (this.mediaRecorderStreaming) {
            this.mediaRecorderStreaming.stop();
            this.mediaRecorderStreaming = null;
          }
          if (videoStream) {
            videoStream.getTracks().forEach(t => t.stop());
          }
          if (this.dummyVideoElement) {
            this.dummyVideoElement.srcObject = null;
            this.dummyVideoElement = null;
          }
          // âœ… AudioContext ì •ë¦¬
          const ctx = (canvas as any)._audioContext;
          if (ctx && ctx.state !== 'closed') {
            ctx.close();
          }
          this.currentStream = null;
          this.staticContentCanvas = null;
        }
      };
    } catch (error) {
      this.mediaRecorderStreaming = null;
      videoStream.getTracks().forEach(t => t.stop());
      if (this.dummyVideoElement) {
        this.dummyVideoElement.srcObject = null;
        this.dummyVideoElement = null;
      }
      // âœ… AudioContext ì •ë¦¬
      const ctx = (canvas as any)._audioContext;
      if (ctx && ctx.state !== 'closed') {
        ctx.close();
      }
      throw error;
    }
  }

  /**
   * ì •ì  ì½˜í…ì¸ ìš© captureStream (iOS 15+)
   */
  private async createStaticCaptureStream(
    canvas: HTMLCanvasElement,
    config: StreamingConfig
  ): Promise<StreamCreationResult> {
    console.log('[AdaptiveStreamManager] Using captureStream for static content');
    
    let stream: MediaStream;
    
    if ('captureStream' in canvas) {
      stream = (canvas as any).captureStream(config.fps);
    } else if ('mozCaptureStream' in canvas) {
      stream = (canvas as any).mozCaptureStream(config.fps);
    } else {
      throw new Error('Canvas captureStream not supported');
    }
    
    if (!stream || stream.getTracks().length === 0) {
      throw new Error('Failed to create static captureStream');
    }
    
    this.currentStream = stream;
    this.staticContentCanvas = canvas;
    
    toast.success(`Static content streaming started (${config.fps}fps)`, { duration: 2000 });
    
    return {
      stream,
      strategy: 'capturestream',
      config,
      cleanup: () => {
        if (this.currentStream) {
          this.currentStream.getTracks().forEach(track => track.stop());
          this.currentStream = null;
        }
        this.staticContentCanvas = null;
      }
    };
  }

  /**
   * ì •ì  ì½˜í…ì¸ ìš© Canvas fallback (iOS < 14.3)
   */
  private async createStaticCanvasStream(
    canvas: HTMLCanvasElement,
    config: StreamingConfig
  ): Promise<StreamCreationResult> {
    console.log('[AdaptiveStreamManager] Using Canvas fallback for static content');
    
    let stream: MediaStream;
    
    if ('captureStream' in canvas) {
      stream = (canvas as any).captureStream(config.fps);
    } else if ('mozCaptureStream' in canvas) {
      stream = (canvas as any).mozCaptureStream(config.fps);
    } else {
      throw new Error('Canvas captureStream not supported');
    }
    
    this.currentStream = stream;
    this.staticContentCanvas = canvas;
    
    toast.info(`Static content streaming (${config.fps}fps, compatibility mode)`, { duration: 2000 });
    
    return {
      stream,
      strategy: 'canvas',
      config,
      cleanup: () => {
        if (this.currentStream) {
          this.currentStream.getTracks().forEach(track => track.stop());
          this.currentStream = null;
        }
        this.staticContentCanvas = null;
      }
    };
  }

  /**
   * ì •ì  ì½˜í…ì¸  ìŠ¤íŠ¸ë¦¼ ì—…ë°ì´íŠ¸ (í˜ì´ì§€ ì „í™˜ ë“±)
   */
  forceStreamUpdate(): void {
    if (!this.currentStream && !this.mediaRecorderStreaming) {
      console.warn('[AdaptiveStreamManager] No active stream to update');
      return;
    }
    
    // MediaRecorder ì‚¬ìš© ì¤‘ì´ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ì²­í¬ì— ë°˜ì˜ë¨
    if (this.mediaRecorderStreaming) {
      console.log('[AdaptiveStreamManager] MediaRecorder will capture changes in next chunk (~1s)');
      return;
    }
    
    // captureStream ì‚¬ìš© ì¤‘ì´ë©´ ì¦‰ì‹œ í”„ë ˆì„ ìš”ì²­
    if (this.currentStream) {
      const videoTrack = this.currentStream.getVideoTracks()[0];
      if (videoTrack && 'requestFrame' in videoTrack) {
        (videoTrack as any).requestFrame();
        console.log('[AdaptiveStreamManager] Forced frame update via requestFrame');
      } else {
        console.warn('[AdaptiveStreamManager] requestFrame not supported on this track');
      }
    }
  }

  /**
   * MediaRecorder ìŠ¤íŠ¸ë¦¼ ìƒì„± (ë¹„ë””ì˜¤ìš©)
   */
  private async createMediaRecorderStream(
    videoElement: HTMLVideoElement,
    config: StreamingConfig,
    onChunkReady?: (blob: Blob, timestamp: number) => void
  ): Promise<StreamCreationResult> {
    if (process.env.NODE_ENV === 'development') {
      console.log('[AdaptiveStreamManager] Using MediaRecorder strategy');
    }
    
    const events: MediaRecorderStreamingEvents = {
      onChunkReady: (blob, timestamp) => {
        if (onChunkReady) {
          onChunkReady(blob, timestamp);
        }
      },
      onError: (error) => {
        console.error('[AdaptiveStreamManager] MediaRecorder error:', error);
        toast.error(`Streaming error: ${error.message}`);
      },
      onStateChange: (state) => {
        if (process.env.NODE_ENV === 'development') {
          console.log('[AdaptiveStreamManager] MediaRecorder state:', state);
        }
      },
      onBitrateUpdate: (bitrate) => {
        if (bitrate < 500000) {
          console.warn('[AdaptiveStreamManager] Low bitrate detected:', bitrate);
        }
      }
    };
    
    this.mediaRecorderStreaming = new MediaRecorderStreaming(events);
    
    try {
      await this.mediaRecorderStreaming.start(videoElement, config);
      
      const dummyStream = new MediaStream();
      this.currentStream = dummyStream;
      
      toast.success('MediaRecorder streaming started (iOS optimized)', { duration: 2000 });
      
      return {
        stream: dummyStream,
        strategy: 'mediarecorder',
        config,
        cleanup: () => {
          this.mediaRecorderStreaming?.stop();
          this.mediaRecorderStreaming = null;
          this.currentStream = null;
        }
      };
    } catch (error) {
      this.mediaRecorderStreaming = null;
      throw error;
    }
  }
  
  /**
   * captureStream ìŠ¤íŠ¸ë¦¼ ìƒì„± (ë¹„ë””ì˜¤ìš©)
   */
  private async createCaptureStream(
    videoElement: HTMLVideoElement,
    config: StreamingConfig
  ): Promise<StreamCreationResult> {
    if (process.env.NODE_ENV === 'development') {
      console.log('[AdaptiveStreamManager] Using captureStream strategy');
    }
    
    let stream: MediaStream | null = null;
    
    if ('captureStream' in videoElement) {
      try {
        stream = (videoElement as any).captureStream(config.fps);
      } catch (e) {
        console.warn('[AdaptiveStreamManager] captureStream failed:', e);
      }
    }
    
    if (!stream && 'mozCaptureStream' in videoElement) {
      try {
        stream = (videoElement as any).mozCaptureStream(config.fps);
      } catch (e) {
        console.warn('[AdaptiveStreamManager] mozCaptureStream failed:', e);
      }
    }
    
    if (!stream || stream.getTracks().length === 0) {
      throw new Error('Failed to create captureStream');
    }
    
    this.currentStream = stream;
    
    toast.success(`Video streaming started (${config.fps}fps)`, { duration: 2000 });
    
    return {
      stream,
      strategy: 'capturestream',
      config,
      cleanup: () => {
        if (this.currentStream) {
          this.currentStream.getTracks().forEach(track => track.stop());
          this.currentStream = null;
        }
      }
    };
  }
  
  /**
   * Canvas ìŠ¤íŠ¸ë¦¼ ìƒì„± (ë¹„ë””ì˜¤ìš© fallback)
   */
  private async createCanvasStream(
    videoElement: HTMLVideoElement,
    config: StreamingConfig,
    ext?: { withSubtitles?: boolean }
  ): Promise<StreamCreationResult> {
    if (process.env.NODE_ENV === 'development') {
      console.log('[AdaptiveStreamManager] Using Canvas fallback strategy');
    }
    
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    if (!ctx) {
      throw new Error('Failed to get canvas context');
    }
    
    canvas.width = videoElement.videoWidth || 1280;
    canvas.height = videoElement.videoHeight || 720;
    
    console.log(`[AdaptiveStreamManager] Canvas size: ${canvas.width}x${canvas.height}`);
    
    const device = getDeviceInfo();
    let desiredFps = config.fps;
    
    // ìë§‰ì´ í™œì„±í™”ëœ ê²½ìš° ì„±ëŠ¥ì— ë”°ë¼ FPS ìë™ ì¡°ì ˆ
    if (ext?.withSubtitles) {
      if (device.isIOS) {
        desiredFps = Math.min(desiredFps, 20);
      }
      
      if (device.performance === 'low') {
        desiredFps = Math.min(desiredFps, 15);
      } else if (device.performance === 'medium') {
        const area = canvas.width * canvas.height;
        desiredFps = area > 1280 * 720 ? Math.min(desiredFps, 20) : Math.min(desiredFps, 24);
      } else {
        const area = canvas.width * canvas.height;
        desiredFps = area > 1920 * 1080 ? Math.min(desiredFps, 24) : desiredFps;
      }
      
      console.log(`[AdaptiveStreamManager] Subtitles enabled - adjusted FPS to ${desiredFps} for device performance: ${device.performance}`);
    }
    
    let stream: MediaStream;
    
    if ('captureStream' in canvas) {
      stream = (canvas as any).captureStream(desiredFps);
    } else if ('mozCaptureStream' in canvas) {
      stream = (canvas as any).mozCaptureStream(desiredFps);
    } else {
      throw new Error('Canvas captureStream not supported');
    }
    
    const draw = () => {
      if (!videoElement.paused && !videoElement.ended) {
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
        if (ext?.withSubtitles) this.drawSubtitles(ctx, canvas.width, canvas.height);
      }
      this.canvasAnimationId = requestAnimationFrame(draw);
    };
    
    draw();
    
    this.currentStream = stream;
    
    toast.info(`Canvas streaming started (${desiredFps}fps, compatibility mode)`, { duration: 2000 });
    
    return {
      stream,
      strategy: 'canvas',
      config: { ...config, fps: desiredFps },
      cleanup: () => {
        if (this.canvasAnimationId) {
          cancelAnimationFrame(this.canvasAnimationId);
          this.canvasAnimationId = null;
        }
        if (this.currentStream) {
          this.currentStream.getTracks().forEach(t => t.stop());
          this.currentStream = null;
        }
      }
    };
  }
  
  /**
   * ìë§‰ ê·¸ë¦¬ê¸° í—¬í¼ ë©”ì„œë“œ
   */
  private drawSubtitles(ctx: CanvasRenderingContext2D, w: number, h: number) {
    const st = useSubtitleStore.getState();
    if (!st.isEnabled || !st.currentCue) return;
    const raw = st.currentCue.text || '';
    const text = raw.replace(/<[^>]+>/g, '');
    const paragraphs = text.split(/\r?\n/);
    
    const sizeMap: Record<string, number> = {
      small: Math.round(h * 0.032),
      medium: Math.round(h * 0.04),
      large: Math.round(h * 0.05),
      xlarge: Math.round(h * 0.06)
    };
    const fontSize = sizeMap[st.style.fontSize] || Math.round(h * 0.04);
    const padX = Math.max(8, Math.round(fontSize * 0.6));
    const padY = Math.max(6, Math.round(fontSize * 0.4));
    const maxTextWidth = Math.floor(w * 0.8); // 80% ìº”ë²„ìŠ¤ í­ ê¸°ì¤€
    
    ctx.font = `${st.style.fontWeight === 'bold' ? 'bold' : 'normal'} ${fontSize}px ${st.style.fontFamily}`;
    ctx.textAlign = 'center';
    ctx.textBaseline = 'alphabetic';
    
    // ìë™ ì¤„ë°”ê¿ˆ ì ìš©
    const lines: string[] = [];
    paragraphs.forEach(p => {
      const wrapped = this.wrapTextByWidth(ctx, p, maxTextWidth);
      wrapped.forEach(l => lines.push(l));
    });
    
    if (lines.length === 0) return;
    
    const lineHeight = Math.round(fontSize * 1.3);
    const longest = lines.reduce((a, b) => (ctx.measureText(a).width > ctx.measureText(b).width ? a : b), '');
    const textWidth = Math.min(maxTextWidth, ctx.measureText(longest).width);
    const boxWidth = textWidth + padX * 2;
    const boxHeight = lines.length * lineHeight + padY * 2;
    
    let y;
    if (st.position === 'top') {
      y = Math.max(boxHeight + padY, Math.round(h * 0.1));
    } else if (st.position === 'bottom') {
      y = h - Math.round(h * 0.08);
    } else if (st.position === 'custom') {
      y = h * (st.customPosition.y / 100);
    } else {
      y = h - Math.round(h * 0.08);
    }
    
    const x = Math.floor(w / 2);
    const boxX = x - Math.floor(boxWidth / 2);
    const boxY = y - boxHeight;
    
    ctx.fillStyle = this.hexToRgba(st.style.backgroundColor, st.style.backgroundOpacity);
    ctx.fillRect(boxX, boxY, boxWidth, boxHeight);
    
    if (st.style.edgeStyle === 'uniform') {
      ctx.lineWidth = Math.max(1, Math.round(fontSize * 0.08));
      ctx.strokeStyle = st.style.edgeColor;
    } else {
      ctx.shadowColor = st.style.edgeColor;
      ctx.shadowBlur = st.style.edgeStyle === 'dropshadow' ? Math.round(fontSize * 0.15) : 0;
      if (st.style.edgeStyle === 'raised') ctx.shadowOffsetY = -Math.round(fontSize * 0.06);
      else if (st.style.edgeStyle === 'depressed') ctx.shadowOffsetY = Math.round(fontSize * 0.06);
      else ctx.shadowOffsetY = 0;
    }
    
    ctx.fillStyle = st.style.color;
    lines.forEach((line, i) => {
      const ty = boxY + padY + lineHeight * (i + 1) - Math.round(fontSize * 0.2);
      if (st.style.edgeStyle === 'uniform') ctx.strokeText(line, x, ty);
      ctx.fillText(line, x, ty);
    });
    
    ctx.shadowBlur = 0;
    ctx.shadowOffsetY = 0;
  }
  
  /**
   * í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ë„ˆë¹„ì— ë§ê²Œ ìë™ ì¤„ë°”ê¿ˆí•˜ëŠ” í—¬í¼ ë©”ì„œë“œ
   */
  private wrapTextByWidth(ctx: CanvasRenderingContext2D, text: string, maxWidth: number): string[] {
    const words = text.split(/\s+/).filter(Boolean);
    if (words.length === 0) return [];
    
    const lines: string[] = [];
    let current = words[0];
    
    for (let i = 1; i < words.length; i++) {
      const candidate = current + ' ' + words[i];
      if (ctx.measureText(candidate).width <= maxWidth) {
        current = candidate;
      } else {
        lines.push(current);
        current = words[i];
      }
    }
    
    lines.push(current);
    return lines;
  }

  /**
   * hex â†’ rgba ë³€í™˜ í—¬í¼ ë©”ì„œë“œ
   */
  private hexToRgba(hex: string, alpha: number) {
    const h = hex.replace('#', '');
    if (h.length === 3) {
      const r = parseInt(h[0] + h[0], 16);
      const g = parseInt(h[1] + h[1], 16);
      const b = parseInt(h[2] + h[2], 16);
      return `rgba(${r},${g},${b},${alpha})`;
    }
    const r = parseInt(h.slice(0, 2), 16);
    const g = parseInt(h.slice(2, 4), 16);
    const b = parseInt(h.slice(4, 6), 16);
    return `rgba(${r},${g},${b},${alpha})`;
  }
  
  /**
   * ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ í™•ì¸
   */
  isStreaming(): boolean {
    if (this.mediaRecorderStreaming) {
      return this.mediaRecorderStreaming.isStreaming();
    }
    
    return this.currentStream !== null;
  }
  
  /**
   * ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  cleanup(): void {
    if (this.mediaRecorderStreaming) {
      this.mediaRecorderStreaming.stop();
      this.mediaRecorderStreaming = null;
    }
    
    if (this.canvasAnimationId) {
      cancelAnimationFrame(this.canvasAnimationId);
      this.canvasAnimationId = null;
    }
    
    if (this.currentStream) {
      this.currentStream.getTracks().forEach(track => track.stop());
      this.currentStream = null;
    }
    
    if (this.dummyVideoElement) {
      this.dummyVideoElement.srcObject = null;
      this.dummyVideoElement = null;
    }
    
    this.staticContentCanvas = null;
  }
}